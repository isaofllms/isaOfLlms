# The Information Security Awareness of Large Language Models

## Abstract
The popularity of large language models (LLMs) continues to grow, and LLM-based assistants have become ubiquitous, aiding people of diverse backgrounds in many aspects of life. Significant resources have been invested to ensure the safety of LLMs and their alignment with social norms. Information security awareness (ISA) is an important safety aspect. ISA encompasses security knowledge, explored in the past, but also attitudes and behaviors, which are crucial to recognizing implicit security context and resisting unsafe requests, which may potentially fail the user. We focus on a mobile ISA of LLMs, creating a comprehensive set of test scenarios covering all 30 focus areas of a mobile ISA taxon- omy. Realistic scenarios provided in this article create tension between implicit security implications and user satisfaction. Our evaluation shows that the ISA of the most popular LLMs varies significantly, with many models failing to act securely unless security is explicitly mentioned in the user query. We also observe that the system prompt can greatly affect ISA. Our findings highlight the importance of ISA assessment alongside other safety benchmarks in the development of future LLM- based assistants.


## The structure of this repository:
